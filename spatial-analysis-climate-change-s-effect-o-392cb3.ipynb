{"cells":[{"cell_type":"markdown","metadata":{"dc":{"key":"3"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 1. Tracking a changing climate\n","![Loxia scotica](https://assets.datacamp.com/production/project_664/img/Loxia.jpg)<p>Climate change is taking place all around the planet right now. In many regions, the effects of climate change can be seen, but birds are particularly vulnerable. Many bird species, if they can, are attempting to migrate north in order to remain in a climate that is favorable for them.</p>\n","<p>Our analysis will use data from the <a href=\"https://www.metoffice.gov.uk/climate/uk/data/ukcp09\">UK Met Office</a> together with records from the <a href=\"https://www.gbif.org/\">Global Biodiversity Information Facility</a> to build our very own species distribution model using machine learning. This model will be able to predict where our bird species of interest is likely to occur in the future - information that is invaluable to conservation organization working on the ground to preserve these species and save them from extinction!</p>\n","<p>In this notebook, we will model the Scottish crossbill (<em>Loxia scotica</em>). The Scottish crossbill is a little bird that lives in Scotland's cold woodlands and feeds on pine seeds. Only 20,000 members of this species are still alive today. This project's code and data sources can be used to any other species we might be interested in studying.</p>\n","<p>We will start by importing the climate data from a local <code>rds</code> file.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"3"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Load in the tidyverse, raster, and sf packages\n","library(tidyverse)\n","library(raster)\n","library(sf)\n","# Read the climate data from an rds file\n","climate  <- read_rds(\"../input/climate-gbif-dataset/climate_raster.rds\")\n","\n","# Have a look at the variables in the climate data\n","colnames(climate)\n","\n","# Convert to SpatialPixelDataFrame for plotting\n","climate_df <- mutate(\n","  .data = climate, \n","  rasters = map(\n","    .x = rasters, \n","    ~ as_tibble(as(.x, \"SpatialPixelsDataFrame\")))) %>%\n","  unnest(cols = c(rasters))"]},{"cell_type":"markdown","metadata":{"dc":{"key":"10"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 2. Mapping a changing climate\n","<p>We have loaded the pre-processed climate data and converted it to a <code>SpatialPixelDataFrame</code>. This data frame now contains all the information we need:</p>\n","<ul>\n","<li>the <code>decade</code> of observation,</li>\n","<li>spatial coordinates (<code>x</code>, <code>y</code>)</li>\n","<li>six selected climatic variables (<code>minimum.temperature</code>, <code>maximum.temperature</code>, <code>rainfall</code>, <code>wind.speed</code>, <code>snow.lying</code>, <code>air.frost</code>)</li>\n","</ul>\n","<p>Visualizing the data is an excellent initial step in any analysis. Visualizing the data ensures that the data import was successful and assists us in developing intuition about the patterns in our dataset. We're dealing with spatial data here, so let's make some maps! We'll start with two maps: one of 1970's climatic circumstances and one of 2010's climatic conditions. Let us choose one of the variables <code>minimum.temperature</code> in our climatic data for now. </p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"10"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["library(ggthemes)\n","\n","# Filter the data to plot\n","ggp_temperature <- climate_df %>%\n","  filter(decade== \"1970\" | decade == \"2010\")  %>% \n","  # Create the plot\n","  ggplot(aes(x = x, y = y)) + geom_tile(aes(fill = minimum.temperature)) +\n","  # Style the plot with options ideal for maps\n","  theme_map() + coord_equal() +\n","  facet_grid(~ decade) + scale_fill_distiller(palette = \"Spectral\") + \n","  theme(legend.title = element_blank(), legend.position = \"bottom\") +\n","  labs(title = \"Minimum of Average Monthly Temperature (Celsius)\", caption = 'Source: MetOffice UK')\n","\n","# Display the map\n","ggp_temperature"]},{"cell_type":"markdown","metadata":{"dc":{"key":"17"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 3. Fieldwork in the digital age â€“ download the data\n","<p>We must now collect records of species occurrence. This used to be the most difficult problem in biogeography. Natural historians like Charles Darwin and Alexander von Humboldt spent years aboard rustic sail ships collecting animal and plant specimens to better understand the natural world. We stand now on the shoulders of giants. Thanks to two organizations, obtaining data is quick and simple:</p>\n","<ul>\n","<li><p><a href=\"https://www.gbif.org/\">The Global Biodiversity Information Facility (GBIF)</a>, an international network and research infrastructure aimed at providing anyone, anywhere, open access to data about life on Earth. We will use their data in this project.</p></li>\n","<li><p><a href=\"https://ropensci.org/\">rOpenSci</a>, a non-profit initiative that develops open source tools for academic data sets. Their package <code>rgbif</code> was used to access the species data.</p></li>\n","</ul>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"17"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["source(\"../input/climate-gbif-dataset/occ_search.R\")\n","\n","# Call the API to get the occurrence records of this species\n","gbif_response <- readRDS(\"../input/climate-gbif-dataset/gbif_response.rds\")\n","\n","# Inspect the class and names of gbif_response\n","class(gbif_response)\n","names(gbif_response)\n","# Print the first six lines of the data element in gbif_response\n","head(gbif_response$data)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"24"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 4.Data cleaning\n","<p>GBIF and rOpenSci have just saved us years of highland exploration with binoculars, camping in mud, rain, and snow, and pursuing crossbills through the forest! However, it is still our responsibility to interpret the data. Specifically, data acquired at this scale can present complications. Fortunately, GBIF includes valuable metadata for each item.</p>\n","<p>Here are some criteria we can use: </p>\n","<ol>\n","<li>\"issues\" - We will only use records where no doubts about the observation were listed.</li>\n","<li>\"license\" - We will only use records under a creative commons license.</li>\n","<li>\"date\" - We will only use records between 1965 and 2015 because that matches our climate dataset.</li>\n","</ol>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"24"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["library(lubridate)\n","\n","birds_dated <- mutate(\n","  .data = gbif_response$data,\n","  # Create a new column specifying the decade of observation\n","  decade = ymd_hms(eventDate) %>% round_date(\"10y\") %>% year())\n","\n","birds_cleaned <- birds_dated %>%\n","  filter(\n","    issues == \"\" &\n","    str_detect(license, \"http://creativecommons.org/\") &\n","    # No records before 1970s decade or after 2010s decade\n","    decade>= \"1970\" & decade <= \"2010\"\n","  ) %>%\n","  transmute(decade = decade, x = decimalLongitude, y = decimalLatitude) %>%\n","  arrange(decade)\n","head(birds_cleaned)\n"]},{"cell_type":"markdown","metadata":{"dc":{"key":"31"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 5. Nesting the data\n","<p>We have cleaned the data, but there is a problem. We want to know the climatic conditions at the location of the bird observation <strong>at the time</strong> of the observation. This is tricky because we have climate data from multiple decades. How do we match each bird observation to the correct climate raster cell?</p>\n","<p>We will use a nifty trick: we can <code>nest()</code> data in a list column. The result is a data frame where the grouping columns do not change, and a list column of aggregated data from each group is added. List columns can hold many different kinds of variables such as vectors, data frames, and even objects. For example, the climate data that we imported earlier was already nested by decade and had a list column (<code>rasters</code>) that contained a <code>rasterStack</code> object for each decade.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"31"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# \"Nest\" the bird data\n","birds_nested <- birds_cleaned  %>%  group_by(decade)  %>% \n","nest(.key = \"presences\")\n","\n","head(birds_nested)\n","\n","# Calculate the total number of records per decade\n","birds_counted <- birds_nested %>%\n","  mutate(n = map_dbl(.x = presences, .f = nrow))\n","\n","head(birds_counted)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"39"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 6. Making things spatial - projecting our observations\n","<p>Excellent! Both our datasets are nested by decade now. We have one more step before we extract the climatic conditions at bird locations. Locations in <code>birds_counted</code> are latitude and longitude coordinates. R doesn't know that these are spatial information. We need to <strong>convert</strong> and <strong>project</strong> our data.</p>\n","<p>Projections are necessary because maps are 2-dimensional, but the earth is 3-dimensional. There is no entirely accurate way to represent the surface of a 3D sphere in 2D. Projections are sets of conventions to help us with this issue. GBIF hosts data from around the world and uses a global projection (WGS84). The Met Office is a UK organization and provides data in the British National Grid projection (BNG).</p>\n","<p>To project spatial data, use Coordinate Reference System (CRS) strings.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"39"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Define geographical projections\n","proj_latlon <- st_crs(\"+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0\")\n","proj_ukgrid <- st_crs(\"+init=epsg:27700\")\n","\n","# Convert records to spatial points and project them\n","birds_presences <- mutate(birds_counted,\n","  presences = map(presences, ~ .x %>%\n","    # Specify the current projection\n","    st_as_sf(coords = c(\"x\", \"y\"), crs = proj_latlon) %>%\n","    # Transform to new projection\n","    st_transform(crs = proj_ukgrid)))"]},{"cell_type":"markdown","metadata":{"dc":{"key":"46"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 7. Extract exactly what we want\n","<p>Now, we can integrate the two datasets and extract the meteorological conditions at each place for the specified decade. Here is where the nested structure is useful! We combine the data frames by their grouping column, ensuring that the data in the list fields are accurately matched. This allows us to work element-by-element on the list column variables using the <code>map()</code> family of operations..</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"46"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Combine the bird data and the climate data in one data frame\n","birds_climate <- full_join(birds_presences, climate, by = \"decade\")\n","\n","presence_data <- map2_df(\n","  .x = birds_climate[[\"rasters\"]],\n","  .y = birds_climate[[\"presences\"]],\n","  # extract the raster values at presence locations\n","  ~ raster::extract(x = .x, y = .y) %>% \n","    as_tibble() %>% \n","    mutate(observation = \"presence\"))\n","head(presence_data)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"53"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 8. Pseudo-absences\n","<p>The classification technique for a machine learning model requires two classes: presences and absences. Our presences are the GBIF observations. Absences are significantly more difficult to obtain. </p>\n","<p>\n","The challenge stems from the imbalance of information between the presences and absences. With a bird observation, we are positive that the bird occurred at that spot, but to be absolutely certain that the bird does not appear anywhere, we would need to regularly monitor the site. </p>\n","<p>\n","One solution to this issue is to simulate \"pseudo-absences.\" Pseudo-absences represent a random sample of the total research population. We assume that the species does not exist at the random sites and hope that the average real likelihood of spotting the bird at these random locations is low enough to provide our algorithm with something to learn. </p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"53"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Define helper function for creating pseudo-absence data\n","create_pseudo_absences <- function(rasters, n, ...) {\n","    set.seed(12345)\n","    sampleRandom(rasters, size = n * 5, sp = TRUE) %>% \n","    raster::extract(rasters, .) %>% as_tibble() %>%\n","    mutate(observation = \"pseudo_absence\")\n","}\n","\n","# Create pseudo-absence proportional to the total number of records per decade\n","pseudo_absence_data <- pmap_df(.l = birds_climate, .f = create_pseudo_absences)\n","\n","\n","# Combine the two datasets\n","model_data <- rbind(presence_data, pseudo_absence_data) %>%\n","  mutate(observation = factor(observation)) %>% na.omit()\n","\n","head(model_data)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"60"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 9. Making models - with caret\n","<p>We are ready to train our model. We will use <code>glmnet</code>,  which fits a generalized logistic regression (<em>glm</em>) with elastic net regularization (<em>net</em>). Our algorithm has several \"hyperparameters\". These are variables used by the machine learning algorithm to learn from the data. They influence the performance of the model and often interact with one another, so it is difficult to know the right settings <em>apriori</em>.</p>\n","<p>To figure out a good set of hyperparameters, we need to try several possible scenarios to see which ones work best. <code>caret</code> makes this easy. All we need to do is define a \"tuning grid\" with sets of possible values for each training parameter. Then use cross-validation to evaluate how well the different combinations of hyperparameters did building the predictive model.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"60"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Load caret and set a reproducible seed\n","library(caret)\n","set.seed(12345)\n","\n","# Create a tuning grid with sets of hyperparameters to try\n","tuneGrid <- expand.grid(alpha = c(0, 0.5, 1), lambda = c(.003, .01, .03, .06))\n","\n","# Create settings for model training\n","trControl <- trainControl(method = 'repeatedcv', number = 5, repeats = 1,\n","  classProbs = TRUE, verboseIter = FALSE, summaryFunction = twoClassSummary)\n","\n","# Fit a statistical model to the data and plot\n","model_fit <- train(\n","  observation ~ ., data = model_data,\n","  method = \"glmnet\", family = \"binomial\", metric = \"ROC\",\n","  tuneGrid = tuneGrid, trControl = trControl)\n","\n","plot(model_fit)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"67"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 10. Prediction probabilities\n","<p>We have constructed our first model of species distribution! Next, we will utilize it to predict the occurrence likelihood of our small crossbill throughout the United Kingdom! We will make forecasts for each decade and each grid cell. Since a logistic regression model has been fitted, we can predict the probability. In our situation, this becomes the \"occurrence probability\" for our species.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"67"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Use our model to make a prediction\n","climate_df[[\"prediction\"]] <- predict(\n","    object = model_fit,\n","    newdata = climate_df,\n","    type = \"prob\")[[\"presence\"]]\n","\n","head(climate_df)"]},{"cell_type":"markdown","metadata":{"dc":{"key":"74"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 11. Visualizing Predictions\n","<p>We have our predictions, but they are not in a digestible format. It is tough to figure out what is going on from that large table of numbers, and it would be even more challenging to convince a politician, the general public, or a local decision maker with it.</p>\n","<p>It would be great to visualize the predictions so we can see the patterns and how they change over time. A picture says more than a thousand words. And what says even more than a picture (at least if you are a geographer)? A colored map! Let us create another map that shows our predictions of a changing climate in the UK, from 1965 to 2015.</p>"]},{"cell_type":"code","execution_count":null,"metadata":{"dc":{"key":"74"},"editable":false,"tags":["sample_code"],"trusted":true,"vscode":{"languageId":"r"}},"outputs":[],"source":["# Load packages gganimate and viridis\n","library(viridis)\n","\n","# Create the plot\n","ggp_changemap <- ggplot(data = climate_df, aes(x = x, y = y, fill = prediction)) +\n","  geom_tile() +\n","  # Style the plot with the appropriate settings for a map\n","  theme_map() + coord_equal() +\n","  scale_fill_viridis(option = \"A\") + theme(legend.position = \"bottom\") +\n","  # Add faceting by decade\n","  facet_grid(~ decade) +\n","  labs(title = 'Habitat Suitability', subtitle = 'by decade',\n","       caption = 'Source:\\nGBIF data and\\nMetOffice UK climate data',\n","       fill = 'Habitat Suitability [0 low - high 1]')\n","\n","# Display the plot\n","ggp_changemap"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2195441,"sourceId":3667674,"sourceType":"datasetVersion"}],"dockerImageVersionId":30186,"isGpuEnabled":false,"isInternetEnabled":false,"language":"r","sourceType":"notebook"},"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"4.0.5"}},"nbformat":4,"nbformat_minor":4}
